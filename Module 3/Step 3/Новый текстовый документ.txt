sudo su root
cd ..
cd ..
cd etc/ssh/

cat ssh_host_rsa_key.pub - копировать в открытый ключ кластера

изменить на актуальный публичный ключ nano ~/.ssh/authorized_keys
отключить проверку пароля sudo nano /etc/ssh/sshd_config 
раскомментировать PermitEmptyPasswords no
рестартануть  sudo service ssh restart
подключиться с авторизацией по ключу ssh root@51.250.51.189 -i /etc/ssh/ssh_host_rsa_key


echo Hello world > hello.txt создать локальный тексовый файл
hadoop fs -mkdir /user/root

hdfs dfs -mkdir /user/root создать папку
hdfs dfs -rm -r /user/root удалить папку
hdfs dfs -ls /user посмотреть в папке
hdfs dfs -ls /user/root посмотреть в папке

hdfs dfs -put /root/hello.txt /user/root переложить текстовый файл в hdfs

hdfs dfs -ls - посмотреть файлы в hdfs
hdfs dfs -text hello.txt открыть файл

hdfs fsck hello.txt -files -blocks -locations - посмотреть блоки и нахождение блоков
hdfs dfs -setrep 2 hello.txt изменить фактор репликации

ssh root@51.250.126.77 -i /etc/ssh/ssh_host_rsa_key подключиться к дата ноде
ssh root@51.250.51.189 -i /etc/ssh/ssh_host_rsa_key подключиться к мастер ноде
cd /hadoop/dfs/data/current


--не работает этот вариант
sudo apt update
sudo apt upgrade

sudo apt-get install awscli установить командную строку awscli aws --version
aws --version

установил на дата ноду aws
aws s3 ls s3://nyc-tlc/trip\ data/ --no-sign-request
aws s3 cp s3://nyc-tlc/trip\ data/yellow_tripdata_2020-12.csv ./ --no-sign-request

hdfs dfs -mkdir /user/root/2019
hadoop distcp -Dfs.s3a.endpoint=s3.amazonaws.com -Dfs.s3a.aws.credentials.provider=org.apache.hadoop.fs.s3a.AnonymousAWSCredentialsProvider s3a://nyc-tlc/trip\ data/yellow_tripdata_2019-1* 2019/

--новый вариант работы с aws

20.12.2022
--сменить пользователя в терминале
sudo su root
user1user1

--подключиться к мастер ноде на кластере
ssh root@51.250.54.226 -i /etc/ssh/ssh_host_rsa_key

--работа с aws
Создадим именованный профиль AWS

aws configure --profile=karpov-user

karpov-user - это имя профиля (можно выбрать любое и в дальнейшем его использовать в командах)

Именованный профиль — это набор настроек и учетных данных, которые можно применить к команде AWS CLI. Когда вы указываете профиль для запуска команды, параметры и учетные данные используются для запуска этой команды. В файлах конфигурации и учетных данных можно хранить несколько именованных профилей. Вы можете указать один профиль по умолчанию, который будет использоваться, если ни один из профилей не указан явно. Другие профили имеют имена, которые можно указать в качестве параметра в команде. Подробнее.

Далее нас попросят ввести ключи, имя региона и формат вывода:

- AWS_ACCESS_KEY -- YCAJEaWZCK9f1rSrcK5RODNa_

- AWS_SECRET_KEY -- YCO8oyvOPdxfBozri_OOZqjPiQrs6R60rrORfNDl

- REGION -- ru-central1

- OUTPUT_FORMAT -- json

И теперь, чтобы посмотреть содержимое бакета, нужно выполнить команду:

aws --profile=karpov-user --endpoint-url=https://storage.yandexcloud.net s3 ls s3://ny-taxi-data/ny-taxi/

--Выберем один из них и скачаем (здесь cp от copy, ./ значит, что мы загрузим файл в текущую директорию):
aws --profile=karpov-user --endpoint-url=https://storage.yandexcloud.net s3 cp s3://ny-taxi-data/ny-taxi/yellow_tripdata_2020-12.csv ./

aws --profile=karpov-user --endpoint-url=https://storage.yandexcloud.net s3 cp s3://ny-taxi-data/ny-taxi/yellow_tripdata_2020-01.csv ./

и т.д все месяцы

Загрузим скачанный файл на HDFS с размером блока 64Мб и двойной репликацией:

hadoop fs -Ddfs.blocksize=67108864 -Ddfs.replication=2 -put yellow_tripdata_2020-12.csv

hdfs fsck yellow_tripdata_2020-12.csv -blocks

hadoop fs -mkdir 2020
aws --profile=karpov-user --endpoint-url=https://storage.yandexcloud.net s3 cp --recursive s3://ny-taxi-data/ny-taxi/ ./2020
hadoop fs -put /root/2020 2020
hadoop fs -ls -h 2020/2020

hadoop fs -text 2020/2020/yellow_tripdata_2020-10.csv | head -n 10
hadoop fs -tail 2020/2020/yellow_tripdata_2020-10.csv

--Шаг 5
Создать бакет Object Storage Бакеты, имя бакета step5
hadoop fs -ls 2020/2020 здесь локально лежат скачанные датасеты amazon такси
hadoop fs -ls -h 2020/2020

aws --profile=k-valiev --endpoint-url=https://storage.yandexcloud.net s3 cp --recursive ./2020 s3://step5/ny-taxi

настройка credentials для aws в облаке Yandex Cloud

Подготовка
Настройка сервисного аккаунта
(Сервисный аккаунт) hadoop-service-account
aws configure --profile=k-valiev
AWS_ACCESS_KEY(Идентификатор ключа) YCAJE6r6YpeJV0nNszKgyI1w4
AWS_SECRET_KEY(Секретный ключ) YCPA4XyVFp2PiS8CvvUvAk9teMmtj3Ss8PKa3IQt
REGION -- ru-central1
OUTPUT_FORMAT -- json

Назначить роли для storage для сервисного аккаунта hadoop-service-account в консоли облака

Теперь можно посмотреть списко файлов в бакете s3 на облаке через свой аккаунт
aws --profile=k-valiev --endpoint-url=https://storage.yandexcloud.net s3 ls s3://step5

!!!ACL бакета добавить FULL CONTROL для сервисного аккаунта

Команда для копирования файлов из локали в бакет s3
aws --profile=k-valiev --endpoint-url=https://storage.yandexcloud.net s3 cp --r
ecursive ./2020 s3://step5/ny-taxi

получить список объектов
aws --profile=k-valiev --endpoint-url=https://storage.yandexcloud.net s3 ls --recursive s3://step5

посмотреть первые 10 строк файла
cat yellow_tripdata_2020-01.csv | head -n 10

Колонки для анализа
payment_type(9), tip_amount(13)

Требования к отчету:
Количество файлов — 1
Формат — csv
Сортировка — Month по возрастанию, Payment type по возрастанию.

Payment type	Month	Tips average amount
Cash	        2020-01	 999.99

--создать папку на неймноде для хранения скриптов маппера и редусера
Открыть в PyCharm терминал Ubuntu
mkdir tmp
mkdir tmp/mapreduce

----
!!!!НЕ ПОМОГЛО
на мастер ноде кластера
sudo vi /etc/ssh/sshd_config
PermitEmptyPasswords yes изменил на yes
раскоментировал PasswordAuthentication no и изменил на no
----
сложит файлы на hdfs hadoop fs -Ddfs.blocksize=67108864 -Ddfs.replication=2 -put yellow_tripdata_2020-12.csv

scp ./*.py root@51.250.54.226:/tmp/mapreduce/ && scp ./run.sh root@51.250.54.226:/tmp/mapreduce/
scp -i /etc/ssh/ssh_host_rsa_key ./*.py root@51.250.54.226:/root/tmp/mapreduce && scp -i /etc/ssh/ssh_host_rsa_key ./run.sh root@51.250.54.226:/root/tmp/mapreduce

в консоли масетр ноды
export MR_OUTPUT=/user/root/output-data

удалить папку перед запуском задания map-reduce
hadoop fs –rm –r $MR_OUTPUT

запуск из папки, в которой лежат скрипты tmp/mapreduce
hadoop jar "$HADOOP_MAPRED_HOME"/hadoop-streaming.jar \
-Dmapred.job.name='Simple streaming job reduce' \
-file mapper.py -mapper mapper.py \
-file reducer.py -reducer reducer.py \
-input s3://step5/ny-taxi/ -output $MR_OUTPUT

--подключиться к мастер ноде на кластере
sudo su root
ssh root@51.250.54.226 -i /etc/ssh/ssh_host_rsa_key
cd tmp
cd mapreduce



VendorID,tpep_pickup_datetime,tpep_dropoff_datetime,passenger_count,trip_distance,RatecodeID,store_and_fwd_flag,PULocationID,DOLocationID,payment_type,fare_amount,extra,mta_tax,tip_amount,tolls_amount,improvement_surcharge,total_amount,congestion_surcharge
1,2020-02-01 00:17:35,2020-02-01 00:30:32,1,2.60,1,N,145,7,1,11,0.5,0.5,2.45,0,0.3,14.75,0
1,2020-02-01 00:32:47,2020-02-01 01:05:36,1,4.80,1,N,45,61,1,21.5,3,0.5,6.3,0,0.3,31.6,2.5
1,2020-02-01 00:31:44,2020-02-01 00:43:28,1,3.20,1,N,186,140,1,11,3,0.5,1,0,0.3,15.8,2.5
2,2020-02-01 00:07:35,2020-02-01 00:31:39,1,4.38,1,N,144,140,1,18,0.5,0.5,3,0,0.3,24.8,2.5
2,2020-02-01 00:51:43,2020-02-01 01:01:29,1,2.28,1,N,238,152,2,9.5,0.5,0.5,0,0,0.3,10.8,0
1,2020-02-01 00:15:49,2020-02-01 00:20:48,2,1.00,1,N,249,107,1,5.5,3,0.5,1.85,0,0.3,11.15,2.5
1,2020-02-01 00:25:31,2020-02-01 00:50:22,2,3.40,1,N,79,256,1,18.5,3,0.5,4.45,0,0.3,26.75,2.5
1,2020-02-01 00:11:15,2020-02-01 00:24:29,1,2.10,1,N,224,68,2,10.5,3,0.5,0,0,0.3,14.3,2.5
2,2020-02-01 00:58:26,2020-02-01 01:02:26,1,.80,1,N,116,42,1,5,0.5,0.5,1.26,0,0.3,7.56,0

ssh root@51.250.126.52 -i /etc/ssh/ssh_host_rsa_key
scp -i /etc/ssh/ssh_host_rsa_key ./*.py root@51.250.126.52:/root/tmp/mapreduce && scp -i /etc/ssh/ssh_host_rsa_key ./run.sh root@51.250.126.52:/root/tmp/mapreduce


which python3

проверка исполнения скрипта на кластере
cat ~/2020/* | /opt/conda/bin/python3 | /root/tmp/mapreduce/mapper.py | /opt/conda/bin/python3 | /root/tmp/mapreduce/reducer.py

посмотреть результаты
hadoop fs -ls /user/root/output-data
hadoop fs -cat /user/root/output-data/part-00000


1       2020-11 2.0
1       2020-02 2.0
1       2020-12 2.0
1       2008-12 3.0
        2020-08 2.0
        2020-09 2.0
        2020-06 1.0
        2020-07 2.0
        2020-04 1.0
        2020-05 0.0
        2020-02 0.0
        2020-03 0.0
        2020-01 0.0
2       2020-08 0.0
5       2020-06 0.0
3       2021-01 0.0
1       2021-06 4.0
2       2008-12 0.0
2       2009-01 0.0
1       2020-06 2.0
3       2020-11 -1.0
3       2020-10 -1.0
5       2020-11 0.0
2       2021-04 0.0
2       2021-05 0.0
2       2021-02 0.0
2       2021-01 0.0
3       2009-01 0.0
4       2020-02 0.0
1       2021-04 2.0
1       2020-05 2.0
4       2020-07 0.0
4       2020-06 0.0
4       2020-05 0.0
4       2020-04 0.0
2       2020-09 0.0
1       2021-05 2.0
1       2003-03 0.0
1       2020-01 2.0
2       2020-03 0.0
2       2020-02 0.0
2       2020-05 0.0
1       2020-08 2.0
2       2020-07 0.0
2       2020-06 0.0
        2020-11 2.0
        2020-10 2.0
        2020-12 2.0
1       2021-01 2.0
1       2020-07 2.0
1       2020-04 2.0
1       2021-02 3.0
1       2020-03 2.0
1       2020-09 2.0
3       2020-12 -1.0
4       2020-09 0.0
2       2002-12 0.0
2       2020-01 0.0
4       2020-08 0.0
3       2020-08 -1.0
3       2020-09 -1.0
5       2020-08 0.0
1       2019-12 2.0
3       2020-04 0.0
2       2019-12 0.0
3       2020-06 -1.0
3       2020-07 -1.0
3       2020-01 -1.0
3       2020-02 -1.0
3       2020-03 -1.0
3       2020-05 -1.0
1       2020-10 2.0
4       2020-10 0.0
4       2020-11 -1.0
4       2020-12 0.0
2       2020-04 0.0
4       2020-03 -1.0
1       2009-01 2.0
2       2020-12 0.0
5       2020-01 0.0
2       2020-10 0.0
2       2020-11 0.0
4       2020-01 0.0
3       2019-12 0.0
2       2003-01 0.0


27.12.2022

Публичный адрес мастер нода 84.201.184.133
sudo su root
ssh root@84.201.184.133 -i /etc/ssh/ssh_host_rsa_key

заходим на кластер и прописываем hive
создаем таблицу с указанием location (это ссылка на данные)
--создать БД на HDFS в папке с данными такси
create database yellow_taxi location 's3a://step5/taxi_data';

когда удалял БД удалились все исходные файлы,
чтобы снова положить в бакет
aws --profile=k-valiev --endpoint-url=https://storage.yandexcloud.net s3 cp --recursive ./2020 s3://step5/ny-taxi
заново:
create database yellow_taxi location 's3a://step5/';

--запуск динамического партиционирования
set hive.exec.dynamic.partition.mode=nonstrict;

--увеличить количество партиций
SET hive.exec.max.dynamic.partitions=100000;
SET hive.exec.max.dynamic.partitions.pernode=100000;


НОВЫЙ КЛАСТЕР 
мастер нода ssh root@84.201.184.13 -i /etc/ssh/ssh_host_rsa_key


29.12.2022
мастер нода ssh root@51.250.54.9 -i /etc/ssh/ssh_host_rsa_key


















